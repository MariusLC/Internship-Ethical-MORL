
Initializing and Normalizing Rewards...
[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.
Reward Normalization 0: -121.06617211873332
Reward Normalization 0: -109.32593920672382
  0%|                                | 72/666666 [00:01<3:33:15, 52.09it/s]/home/lechapelier/Documents/Stage M2/Internship-Ethical-MORL/moral_rl/moral/ppo.py:50: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)
  trajectory_states = torch.tensor(tau['states']).float().to(device)





  0%|                              | 369/666666 [00:53<26:48:32,  6.90it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/lechapelier/Documents/Stage M2/Internship-Ethical-MORL/moral_rl/moral/moral_train.py", line 240, in <module>
    update_policy(ppo, dataset, optimizer, config.gamma, config.epsilon, config.ppo_epochs,
  File "/home/lechapelier/Documents/Stage M2/Internship-Ethical-MORL/moral_rl/moral/ppo.py", line 129, in update_policy
    action_log_probabilities, critic_values, action_entropy = ppo.evaluate_trajectory(tau)
  File "/home/lechapelier/Documents/Stage M2/Internship-Ethical-MORL/moral_rl/moral/ppo.py", line 52, in evaluate_trajectory
    action_probabilities, critic_values = self.forward(trajectory_states)
  File "/home/lechapelier/Documents/Stage M2/Internship-Ethical-MORL/moral_rl/moral/ppo.py", line 33, in forward
    x = self.relu(self.l2(x))
  File "/home/lechapelier/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/lechapelier/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/lechapelier/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
KeyboardInterrupt