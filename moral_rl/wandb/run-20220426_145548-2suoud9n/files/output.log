
Initializing and Normalizing Rewards...
[W NNPACK.cpp:51] Could not initialize NNPACK! Reason: Unsupported hardware.
Reward Normalization 0: -118.75174639067716
Reward Normalization 0: -111.76136751528139
  0%|                                                                                             | 72/666666 [00:02<5:07:57, 36.08it/s]/home/lechapelier/Documents/Stage M2/Internship-Ethical-MORL/moral_rl/moral/ppo.py:49: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)
  trajectory_states = torch.tensor(tau['states']).float().to(device)





















































































































































































































































































































  2%|█▋                                                                                        | 12800/666666 [36:30<5:00:23, 36.28it/s]
Found trajectory pair: (array([1., 2., 1.]), array([0., 2., 0.]))
Corresponding best delta: [ 1.          0.05690044 -1.20500025]

  2%|█▋                                                                                       | 12817/666666 [36:40<51:54:21,  3.50it/s]































































































